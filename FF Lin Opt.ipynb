{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251c2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0d8ec029cf96>:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  prices_df['Name'] = prices_df['Name'].str.replace(' Jr.','')\n",
      "<ipython-input-9-0d8ec029cf96>:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  prices_df['Name'] = prices_df['Name'].str.replace(' Sr.','')\n",
      "<ipython-input-9-0d8ec029cf96>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  prices_df['Name'] = prices_df['Name'].str.replace('D.J.','DJ')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "prices_df = pd.read_excel('Fanduel_Player_Prices.xlsx')\n",
    "\n",
    "prices_df['Name'] = prices_df['Player'].str.split('(').str[0].str[0:-1]\n",
    "prices_df['Team'] = prices_df['Player'].apply(lambda st: st[st.find(\"(\")+1:st.find(\" - \")])\n",
    "prices_df['Pos'] = prices_df['Player'].apply(lambda st: st[st.find(\" - \")+3:st.find(\")\")])\n",
    "\n",
    "prices_df['Team'] = prices_df['Team'].str.replace('JAC','JAX')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace(' Jr.','')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace(' Sr.','')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace(' IV','')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace(' III','')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace(' II','')\n",
    "#prices_df['Name'] = prices_df['Name'].str.replace('A.J.','AJ')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace('D.J.','DJ')\n",
    "#prices_df['Name'] = prices_df['Name'].str.replace('K.J.','KJ')\n",
    "prices_df['Name'] = prices_df['Name'].str.replace('Ken Walker','Kenneth Walker')\n",
    "prices_df['Key'] = prices_df['Name'] + '-' + prices_df['Team']\n",
    "\n",
    "prices_df.to_csv('Fanduel_Player_Prices_Clean.csv', index=False)\n",
    "#prices_df.sort_values(by='Price', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9942a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65f80680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "week_num = 7\n",
    "\n",
    "response = requests.get(\"https://www.rotowire.com/betting/nfl/player-props.php\")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(\"Error fetching page\")\n",
    "    exit()\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "obj = soup.find_all('div')\n",
    "obj2 = str(obj[0])\n",
    "\n",
    "# initializing substrings\n",
    "sub1 = \"data: [{\"\n",
    "sub2 = \"}]\"\n",
    "idx0 = 1\n",
    "idx1 = 1\n",
    "idx2 = 1\n",
    "str2 = ''\n",
    "str1 = ''\n",
    "\n",
    "try:\n",
    "    while 1>0:\n",
    "        if idx0 == -1 or idx1 == -1 or idx2 == -1:\n",
    "            #print('complete')\n",
    "            break\n",
    "        \n",
    "        #print('idx0')\n",
    "        #print(idx0)\n",
    "        \n",
    "        idx1 = obj2.find(sub1, idx0)\n",
    "        #print('idx1') \n",
    "        #print(idx1)\n",
    "        \n",
    "        idx2 = obj2.find(sub2, idx1)\n",
    "        #print('idx2') \n",
    "        #print(idx2)\n",
    "        \n",
    "        str1 = obj2[idx1:idx2+1]\n",
    "\n",
    "        idx0 = idx2\n",
    "        idx1 = idx2\n",
    "        idx2 = idx2+1\n",
    "\n",
    "        #print(str1)\n",
    "        #print('')\n",
    "\n",
    "        str2 = str2 + str1\n",
    "except:\n",
    "    pass\n",
    "\n",
    "str2 = str2.replace('data: [', '')\n",
    "str2 = str2.strip()\n",
    "str2\n",
    "\n",
    "# initializing substrings\n",
    "sub1 = \"gameID\"\n",
    "sub2 = \"}\"\n",
    "idx0 = 1\n",
    "idx1 = 1\n",
    "idx2 = 1\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "ls = []\n",
    "\n",
    "while 1>0:\n",
    "    #print('idx0')\n",
    "    #print(idx0)\n",
    "\n",
    "    idx1 = str2.find(sub1, idx0)\n",
    "    #print('idx1') \n",
    "    #print(idx1)\n",
    "\n",
    "    idx2 = str2.find(sub2, idx1)\n",
    "    #print('idx2') \n",
    "    #print(idx2)\n",
    "    \n",
    "    if idx0 == -1 or idx1 == -1 or idx2 == -1:\n",
    "        print('complete')\n",
    "        break\n",
    "\n",
    "    str3 = str2[idx1-2:idx2+1]\n",
    "    \n",
    "    json_obj = json.loads(str3)\n",
    "    df = pd.json_normalize(json_obj)\n",
    "    \n",
    "    df2 = pd.concat([df, df2])\n",
    "    #print(json_obj)\n",
    "    #print(str3)\n",
    "\n",
    "    idx0 = idx2\n",
    "    idx1 = idx2\n",
    "    idx2 = idx2+1\n",
    "\n",
    "dt = datetime.now()    \n",
    "df2['week'] = week_num\n",
    "df2['runtime'] = dt\n",
    "#df2.to_csv('ff_test.csv', index=False)\n",
    "df2.to_csv('ff_test.csv', index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2d1329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-0d90dd513801>:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['recyds'] = df4['recyds'].fillna(0)\n",
      "<ipython-input-46-0d90dd513801>:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['anytd'] = df4['anytd'].fillna(5000)\n",
      "<ipython-input-46-0d90dd513801>:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['rushyds'] = df4['rushyds'].fillna(0)\n",
      "<ipython-input-46-0d90dd513801>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['passyds'] = df4['passyds'].fillna(0)\n",
      "<ipython-input-46-0d90dd513801>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['recs'] = df4['recs'].fillna(0)\n",
      "<ipython-input-46-0d90dd513801>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['anytd_pct'] = np.where(df4['anytd']<0,abs(df4['anytd'])/(abs(df4['anytd'])+100), np.where(df4['anytd']>0,100/(df4['anytd']+100),0))\n",
      "<ipython-input-46-0d90dd513801>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['recyds_fpts'] = (df4['recyds']/10)\n",
      "<ipython-input-46-0d90dd513801>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['td_fpts'] = (df4['anytd_pct']*6)\n",
      "<ipython-input-46-0d90dd513801>:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['rush_fpts'] = (df4['rushyds']/10)\n",
      "<ipython-input-46-0d90dd513801>:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['passyds_fpts'] = (df4['passyds']/25*1.5)\n",
      "<ipython-input-46-0d90dd513801>:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['recs_fpts'] = df4['recs']*0.5\n",
      "<ipython-input-46-0d90dd513801>:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['points'] = df4['recyds_fpts'] + df4['td_fpts'] + df4['rush_fpts'] + df4['passyds_fpts'] + df4['recs_fpts']\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('ff_test.csv')\n",
    "df2 = df2[df2['week']==99]\n",
    "\n",
    "#max_run_ts = df2['runtime'].max()\n",
    "#df2 = df2[df2['runtime']==max_run_ts]\n",
    "#df2 = df2[df2['runtime']==dt]\n",
    "#print(dt)\n",
    "\n",
    "over_constant = 110\n",
    "yds_div = 2.5\n",
    "recs_div = 25\n",
    "\n",
    "df2[['draftkings_recs','draftkings_rushrec','draftkings_recyds','draftkings_rushyds','mgm_recs','mgm_rushrec','mgm_recyds','mgm_rushyds','pointsbet_recs','pointsbet_rushrec','pointsbet_recyds','pointsbet_rushyds','fanduel_recs','fanduel_rushrec','fanduel_recyds','fanduel_rushyds','draftkings_comp','draftkings_passatt','draftkings_passyds','fanduel_comp','fanduel_passatt','fanduel_passyds','mgm_comp','mgm_passatt','mgm_passyds','pointsbet_comp','pointsbet_passatt','pointsbet_passyds','mgm_firsttd','mgm_anytd','mgm_lasttd','mgm_twotd','mgm_threetd','draftkings_firsttd','draftkings_anytd','draftkings_lasttd','draftkings_twotd','draftkings_threetd','fanduel_firsttd','fanduel_anytd','fanduel_lasttd','fanduel_twotd','fanduel_threetd','pointsbet_firsttd','pointsbet_anytd','pointsbet_lasttd','pointsbet_twotd','pointsbet_threetd','draftkings_rushydsUnder','draftkings_rushydsOver','fanduel_rushydsUnder','fanduel_rushydsOver','mgm_rushydsUnder','mgm_rushydsOver','pointsbet_rushydsUnder','pointsbet_rushydsOver','draftkings_recydsUnder','draftkings_recydsOver','fanduel_recydsUnder','fanduel_recydsOver','mgm_recydsUnder','mgm_recydsOver','pointsbet_recydsUnder','pointsbet_recydsOver','draftkings_rushrecUnder','draftkings_rushrecOver','mgm_rushrecUnder','mgm_rushrecOver','fanduel_rushrecUnder','fanduel_rushrecOver','pointsbet_rushrecUnder','pointsbet_rushrecOver','draftkings_recsUnder','draftkings_recsOver','mgm_recsUnder','mgm_recsOver','fanduel_recsUnder','fanduel_recsOver','pointsbet_recsUnder','pointsbet_recsOver','fanduel_passydsUnder','fanduel_passydsOver','mgm_passydsUnder','mgm_passydsOver','pointsbet_passydsUnder','pointsbet_passydsOver','draftkings_passydsUnder','draftkings_passydsOver','draftkings_passattUnder','draftkings_passattOver','fanduel_passattUnder','fanduel_passattOver','mgm_passattUnder','mgm_passattOver','pointsbet_passattUnder','pointsbet_passattOver','fanduel_compUnder','fanduel_compOver','mgm_compUnder','mgm_compOver','draftkings_compUnder','draftkings_compOver','pointsbet_compUnder','pointsbet_compOver','draftkings_threetdUnder','draftkings_threetdOver','fanduel_threetdUnder','fanduel_threetdOver','mgm_threetdUnder','mgm_threetdOver','pointsbet_threetdUnder','pointsbet_threetdOver','draftkings_twotdUnder','draftkings_twotdOver','pointsbet_twotdUnder','pointsbet_twotdOver','fanduel_twotdUnder','fanduel_twotdOver','mgm_twotdUnder','mgm_twotdOver','mgm_lasttdUnder','mgm_lasttdOver','draftkings_lasttdUnder','draftkings_lasttdOver','fanduel_lasttdUnder','fanduel_lasttdOver','pointsbet_lasttdUnder','pointsbet_lasttdOver','mgm_anytdUnder','mgm_anytdOver','draftkings_anytdUnder','draftkings_anytdOver','fanduel_anytdUnder','fanduel_anytdOver','pointsbet_anytdUnder','pointsbet_anytdOver','mgm_firsttdUnder','mgm_firsttdOver','draftkings_firsttdUnder','draftkings_firsttdOver','fanduel_firsttdUnder','fanduel_firsttdOver','pointsbet_firsttdUnder','pointsbet_firsttdOver']] = df2[['draftkings_recs','draftkings_rushrec','draftkings_recyds','draftkings_rushyds','mgm_recs','mgm_rushrec','mgm_recyds','mgm_rushyds','pointsbet_recs','pointsbet_rushrec','pointsbet_recyds','pointsbet_rushyds','fanduel_recs','fanduel_rushrec','fanduel_recyds','fanduel_rushyds','draftkings_comp','draftkings_passatt','draftkings_passyds','fanduel_comp','fanduel_passatt','fanduel_passyds','mgm_comp','mgm_passatt','mgm_passyds','pointsbet_comp','pointsbet_passatt','pointsbet_passyds','mgm_firsttd','mgm_anytd','mgm_lasttd','mgm_twotd','mgm_threetd','draftkings_firsttd','draftkings_anytd','draftkings_lasttd','draftkings_twotd','draftkings_threetd','fanduel_firsttd','fanduel_anytd','fanduel_lasttd','fanduel_twotd','fanduel_threetd','pointsbet_firsttd','pointsbet_anytd','pointsbet_lasttd','pointsbet_twotd','pointsbet_threetd','draftkings_rushydsUnder','draftkings_rushydsOver','fanduel_rushydsUnder','fanduel_rushydsOver','mgm_rushydsUnder','mgm_rushydsOver','pointsbet_rushydsUnder','pointsbet_rushydsOver','draftkings_recydsUnder','draftkings_recydsOver','fanduel_recydsUnder','fanduel_recydsOver','mgm_recydsUnder','mgm_recydsOver','pointsbet_recydsUnder','pointsbet_recydsOver','draftkings_rushrecUnder','draftkings_rushrecOver','mgm_rushrecUnder','mgm_rushrecOver','fanduel_rushrecUnder','fanduel_rushrecOver','pointsbet_rushrecUnder','pointsbet_rushrecOver','draftkings_recsUnder','draftkings_recsOver','mgm_recsUnder','mgm_recsOver','fanduel_recsUnder','fanduel_recsOver','pointsbet_recsUnder','pointsbet_recsOver','fanduel_passydsUnder','fanduel_passydsOver','mgm_passydsUnder','mgm_passydsOver','pointsbet_passydsUnder','pointsbet_passydsOver','draftkings_passydsUnder','draftkings_passydsOver','draftkings_passattUnder','draftkings_passattOver','fanduel_passattUnder','fanduel_passattOver','mgm_passattUnder','mgm_passattOver','pointsbet_passattUnder','pointsbet_passattOver','fanduel_compUnder','fanduel_compOver','mgm_compUnder','mgm_compOver','draftkings_compUnder','draftkings_compOver','pointsbet_compUnder','pointsbet_compOver','draftkings_threetdUnder','draftkings_threetdOver','fanduel_threetdUnder','fanduel_threetdOver','mgm_threetdUnder','mgm_threetdOver','pointsbet_threetdUnder','pointsbet_threetdOver','draftkings_twotdUnder','draftkings_twotdOver','pointsbet_twotdUnder','pointsbet_twotdOver','fanduel_twotdUnder','fanduel_twotdOver','mgm_twotdUnder','mgm_twotdOver','mgm_lasttdUnder','mgm_lasttdOver','draftkings_lasttdUnder','draftkings_lasttdOver','fanduel_lasttdUnder','fanduel_lasttdOver','pointsbet_lasttdUnder','pointsbet_lasttdOver','mgm_anytdUnder','mgm_anytdOver','draftkings_anytdUnder','draftkings_anytdOver','fanduel_anytdUnder','fanduel_anytdOver','pointsbet_anytdUnder','pointsbet_anytdOver','mgm_firsttdUnder','mgm_firsttdOver','draftkings_firsttdUnder','draftkings_firsttdOver','fanduel_firsttdUnder','fanduel_firsttdOver','pointsbet_firsttdUnder','pointsbet_firsttdOver']].apply(pd.to_numeric)\n",
    "df2 = df2[['gameID','playerID','name','team','opp','draftkings_recyds','draftkings_recydsOver','mgm_recyds','mgm_recydsOver','pointsbet_recyds','pointsbet_recydsOver','fanduel_recyds','fanduel_recydsOver','draftkings_anytd','draftkings_anytdOver','mgm_anytd','mgm_anytdOver','pointsbet_anytd','pointsbet_anytdOver','fanduel_anytd','fanduel_anytdOver','draftkings_rushyds','draftkings_rushydsOver','mgm_rushyds','mgm_rushydsOver','pointsbet_rushyds','pointsbet_rushydsOver','fanduel_rushyds','fanduel_rushydsOver','draftkings_passyds','draftkings_passydsOver','mgm_passyds','mgm_passydsOver','pointsbet_passyds','pointsbet_passydsOver','fanduel_passyds','fanduel_passydsOver','draftkings_recs','draftkings_recsOver','mgm_recs','mgm_recsOver','pointsbet_recs','pointsbet_recsOver','fanduel_recs','fanduel_recsOver','runtime']]\n",
    "\n",
    "df2['draftkings_recyds'] = np.where(df2['draftkings_recydsOver']<0,df2['draftkings_recyds']-(df2['draftkings_recydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['draftkings_recyds']-(df2['draftkings_recydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "df2['mgm_recyds'] = np.where(df2['mgm_recydsOver']<0,df2['mgm_recyds']-(df2['mgm_recydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['mgm_recyds']-(df2['mgm_recydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "df2['pointsbet_recyds'] = np.where(df2['pointsbet_recydsOver']<0,df2['pointsbet_recyds']-(df2['pointsbet_recydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['pointsbet_recyds']-(df2['pointsbet_recydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "df2['fanduel_recyds'] = np.where(df2['fanduel_recydsOver']<0,df2['fanduel_recyds']-(df2['fanduel_recydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['fanduel_recyds']-(df2['fanduel_recydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "\n",
    "df2['draftkings_rushyds'] = np.where(df2['draftkings_rushydsOver']<0,df2['draftkings_rushyds']-(df2['draftkings_rushydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['draftkings_rushyds']-(df2['draftkings_rushydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "df2['mgm_rushyds'] = np.where(df2['mgm_rushydsOver']<0,df2['mgm_rushyds']-(df2['mgm_rushydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['mgm_rushyds']-(df2['mgm_rushydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "df2['pointsbet_rushyds'] = np.where(df2['pointsbet_rushydsOver']<0,df2['pointsbet_rushyds']-(df2['pointsbet_rushydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['pointsbet_rushyds']-(df2['pointsbet_rushydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "df2['fanduel_rushyds'] = np.where(df2['fanduel_rushydsOver']<0,df2['fanduel_rushyds']-(df2['fanduel_rushydsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/yds_div,df2['fanduel_rushyds']-(df2['fanduel_rushydsOver'].mask(pd.isnull, over_constant)-over_constant)/yds_div)\n",
    "\n",
    "df2['draftkings_passyds'] = np.where(df2['draftkings_passydsOver']<0,df2['draftkings_passyds']-(df2['draftkings_passydsOver'].mask(pd.isnull, -1*over_constant)+over_constant),df2['draftkings_passyds']-(df2['draftkings_passydsOver'].mask(pd.isnull, over_constant)-over_constant))\n",
    "df2['mgm_passyds'] = np.where(df2['mgm_passydsOver']<0,df2['mgm_passyds']-(df2['mgm_passydsOver'].mask(pd.isnull, -1*over_constant)+over_constant),df2['mgm_passyds']-(df2['mgm_passydsOver'].mask(pd.isnull, over_constant)-over_constant))\n",
    "df2['pointsbet_passyds'] = np.where(df2['pointsbet_passydsOver']<0,df2['pointsbet_passyds']-(df2['pointsbet_passydsOver'].mask(pd.isnull, -1*over_constant)+over_constant),df2['pointsbet_passyds']-(df2['pointsbet_passydsOver'].mask(pd.isnull, over_constant)-over_constant))\n",
    "df2['fanduel_passyds'] = np.where(df2['fanduel_passydsOver']<0,df2['fanduel_passyds']-(df2['fanduel_passydsOver'].mask(pd.isnull, -1*over_constant)+over_constant),df2['fanduel_passyds']-(df2['fanduel_passydsOver'].mask(pd.isnull, over_constant)-over_constant))\n",
    "\n",
    "df2['draftkings_recs'] = np.where(df2['draftkings_recsOver']<0,df2['draftkings_recs']-(df2['draftkings_recsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/recs_div,df2['draftkings_recs']-(df2['draftkings_recsOver'].mask(pd.isnull, over_constant)-over_constant)/recs_div)\n",
    "df2['mgm_recs'] = np.where(df2['mgm_recsOver']<0,df2['mgm_recs']-(df2['mgm_recsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/recs_div,df2['mgm_recs']-(df2['mgm_recsOver'].mask(pd.isnull, over_constant)-over_constant)/recs_div)\n",
    "df2['pointsbet_recs'] = np.where(df2['pointsbet_recsOver']<0,df2['pointsbet_recs']-(df2['pointsbet_recsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/recs_div,df2['pointsbet_recs']-(df2['pointsbet_recsOver'].mask(pd.isnull, over_constant)-over_constant)/recs_div)\n",
    "df2['fanduel_recs'] = np.where(df2['fanduel_recsOver']<0,df2['fanduel_recs']-(df2['fanduel_recsOver'].mask(pd.isnull, -1*over_constant)+over_constant)/recs_div,df2['fanduel_recs']-(df2['fanduel_recsOver'].mask(pd.isnull, over_constant)-over_constant)/recs_div)\n",
    "\n",
    "#df2\n",
    "#df2.sort_values(by='draftkings_passydsOver', ascending = True).head(5)\n",
    "#df2.to_csv('test.csv')\n",
    "df2 = df2[['gameID','playerID','name','team','opp','draftkings_recyds','mgm_recyds','pointsbet_recyds','fanduel_recyds','draftkings_anytd','mgm_anytd','pointsbet_anytd','fanduel_anytd','draftkings_rushyds','mgm_rushyds','pointsbet_rushyds','fanduel_rushyds','draftkings_passyds','mgm_passyds','pointsbet_passyds','fanduel_passyds','draftkings_recs', 'mgm_recs', 'pointsbet_recs', 'fanduel_recs', 'runtime']]\n",
    "df3 = df2.groupby(['gameID','playerID','name','team','opp','runtime']).max().reset_index()\n",
    "\n",
    "#Optimistic\n",
    "#df3['recyds'] = df3[['draftkings_recyds', 'mgm_recyds', 'pointsbet_recyds', 'fanduel_recyds']].max(axis=1)\n",
    "#df3['anytd'] = df3[['draftkings_anytd', 'mgm_anytd', 'pointsbet_anytd', 'fanduel_anytd']].min(axis=1)\n",
    "#df3['rushyds'] = df3[['draftkings_rushyds', 'mgm_rushyds', 'pointsbet_rushyds', 'fanduel_rushyds']].max(axis=1)\n",
    "#df3['passyds'] = df3[['draftkings_passyds', 'mgm_passyds', 'pointsbet_passyds', 'fanduel_passyds']].max(axis=1)\n",
    "#df3['recs'] = df3[['draftkings_recs', 'mgm_recs', 'pointsbet_recs', 'fanduel_recs']].max(axis=1)\n",
    "\n",
    "#Safe\n",
    "df3['recyds'] = df3[['draftkings_recyds', 'mgm_recyds', 'pointsbet_recyds', 'fanduel_recyds']].min(axis=1)\n",
    "df3['anytd'] = df3[['draftkings_anytd', 'mgm_anytd', 'pointsbet_anytd', 'fanduel_anytd']].max(axis=1)\n",
    "df3['rushyds'] = df3[['draftkings_rushyds', 'mgm_rushyds', 'pointsbet_rushyds', 'fanduel_rushyds']].min(axis=1)\n",
    "df3['passyds'] = df3[['draftkings_passyds', 'mgm_passyds', 'pointsbet_passyds', 'fanduel_passyds']].min(axis=1)\n",
    "df3['recs'] = df3[['draftkings_recs', 'mgm_recs', 'pointsbet_recs', 'fanduel_recs']].min(axis=1)\n",
    "\n",
    "#df4 = df3[['gameID','playerID','name','team','opp','recyds','anytd','rushyds','passyds']]\n",
    "df4 = df3[['gameID','playerID','name','team','opp','recyds','anytd','rushyds','passyds','recs','runtime']]\n",
    "df4['recyds'] = df4['recyds'].fillna(0)\n",
    "df4['anytd'] = df4['anytd'].fillna(5000)\n",
    "df4['rushyds'] = df4['rushyds'].fillna(0)\n",
    "df4['passyds'] = df4['passyds'].fillna(0)\n",
    "df4['recs'] = df4['recs'].fillna(0)\n",
    "\n",
    "df4['anytd_pct'] = np.where(df4['anytd']<0,abs(df4['anytd'])/(abs(df4['anytd'])+100), np.where(df4['anytd']>0,100/(df4['anytd']+100),0))\n",
    "#df4['anytd_pct'] = np.where(df4['anytd_pct']>0.5,1/df4['anytd_pct'],df4['anytd_pct'])\n",
    "\n",
    "#df4['anytd_pct'] = df4['anytd'].rank(pct = True, method='min')\n",
    "#df4['anytd_pct'] = 1-df4['anytd_pct']\n",
    "\n",
    "df4['recyds_fpts'] = (df4['recyds']/10)\n",
    "df4['td_fpts'] = (df4['anytd_pct']*6)\n",
    "df4['rush_fpts'] = (df4['rushyds']/10)\n",
    "df4['passyds_fpts'] = (df4['passyds']/25*1.5)\n",
    "df4['recs_fpts'] = df4['recs']*0.5\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#df4[['recyds_scaler','anytd_scaler','rushyds_scaler','passyds_scaler']] = scaler.fit_transform(df4[['recyds','anytd','rushyds','passyds']])\n",
    "#df4['anytd_scaler'] = 1 - df4['anytd_scaler']\n",
    "\n",
    "#df4['points'] = df4['recyds_fpts'] + df4['td_fpts'] + df4['rush_fpts'] + df4['passyds_fpts']\n",
    "df4['points'] = df4['recyds_fpts'] + df4['td_fpts'] + df4['rush_fpts'] + df4['passyds_fpts'] + df4['recs_fpts']\n",
    "#df4.sort_values(by='proj_pts2', ascending=False).head(50)\n",
    "df4.to_csv('ff_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5d8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from pulp import *\n",
    "import pandas as pd\n",
    "\n",
    "prices_df = pd.read_csv('Fanduel_Player_Prices_Clean.csv')\n",
    "df = pd.read_csv('ff_test2.csv')\n",
    "\n",
    "df['Key'] = df['name'] + '-' + df['team']\n",
    "df = pd.merge(df, prices_df, on='Key', how='left')\n",
    "df['Value'] = np.where(df['Price']>0,df['points']/df['Price']*1000,0)\n",
    "df.to_csv('ff_test3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ef5fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 players\n",
      "Variables:\n",
      "\n",
      "QB_Kyler_Murray = 1.0\n",
      "RB_Aaron_Jones = 1.0\n",
      "RB_Christian_McCaffrey = 1.0\n",
      "RB_Deon_Jackson = 1.0\n",
      "TE_Hayden_Hurst = 1.0\n",
      "WR_Brandon_Aiyuk = 1.0\n",
      "WR_Marquez_Valdes_Scantling = 1.0\n",
      "WR_Stefon_Diggs = 1.0\n",
      "---------------------------------------\n",
      "\n",
      "Constraints:\n",
      "8300.0*1.0 + 7300.0*1.0 + 8700.0*1.0 + 5600.0*1.0 + 4900.0*1.0 + 5800.0*1.0 + 5800.0*1.0 + 8900.0*1.0 = 55300.0\n",
      "---------------------------------------\n",
      "\n",
      "Score:\n",
      "20.74*1.0 + 13.359302325581394*1.0 + 15.536666666666664*1.0 + 9.257692307692308*1.0 + 6.963478260869565*1.0 + 9.06*1.0 + 8.746666666666666*1.0 + 15.46*1.0 = 99.12380622747659\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ff_test3.csv') \n",
    "df = df[df['Price']>0]\n",
    "\n",
    "n = len(pd.unique(df['playerID']))\n",
    "print(str(n) + ' players')\n",
    "\n",
    "#df['points'] = df['points']-df['td_fpts']\n",
    "\n",
    "#ls = []\n",
    "df = df[~df['name'].isin(ls)]\n",
    "df = df[~df['Team'].isin(['PHI','DAL','DEN','LAC'])]\n",
    "#df['cap'] = np.where(df['Price'].between(4000, 5900), 1, 0)\n",
    "\n",
    "SALARY_CAP = 60000-4300\n",
    "\n",
    "salaries = {}\n",
    "points = {}\n",
    "#caps = {}\n",
    "\n",
    "for pos in df.Pos.unique():\n",
    "    available_pos = df[df.Pos == pos]\n",
    "    salary = list(available_pos[[\"name\",\"Price\"]].set_index(\"name\").to_dict().values())[0]\n",
    "    point = list(available_pos[[\"name\",\"points\"]].set_index(\"name\").to_dict().values())[0]\n",
    "    cap = list(available_pos[[\"name\",\"cap\"]].set_index(\"name\").to_dict().values())[0]\n",
    "    salaries[pos] = salary\n",
    "    points[pos] = point\n",
    "    #caps[pos] = cap\n",
    "    \n",
    "pos_num_available_max = {\n",
    "    \"QB\": 1,\n",
    "    \"RB\": 3,\n",
    "    \"WR\": 4,\n",
    "    \"TE\": 2\n",
    "}\n",
    "\n",
    "pos_num_available_min = {\n",
    "    \"QB\": 1,\n",
    "    \"RB\": 2,\n",
    "    \"WR\": 3,\n",
    "    \"TE\": 1\n",
    "}\n",
    "\n",
    "total_players = 8\n",
    "\n",
    "_vars = {k: LpVariable.dict(k, v, cat=\"Binary\") for k, v in points.items()}\n",
    "\n",
    "prob = LpProblem(\"Fantasy\", LpMaximize)\n",
    "rewards = []\n",
    "costs = []\n",
    "sal_constraints = []\n",
    "\n",
    "# Setting up the reward\n",
    "for k, v in _vars.items():\n",
    "    costs += lpSum([salaries[k][i] * _vars[k][i] for i in v])\n",
    "    rewards += lpSum([points[k][i] * _vars[k][i] for i in v])\n",
    "    prob += lpSum([_vars[k][i] for i in v]) >= pos_num_available_min[k]\n",
    "    prob += lpSum([_vars[k][i] for i in v]) <= pos_num_available_max[k]\n",
    "    #sal_constraints += lpSum([caps[k][i] * _vars[k][i] for i in v])\n",
    "\n",
    "#prob += lpSum(sal_constraints) >= 4\n",
    "prob += lpSum(_vars) == total_players\n",
    "prob += lpSum(rewards)\n",
    "prob += lpSum(costs) <= SALARY_CAP\n",
    "\n",
    "prob.solve()\n",
    "\n",
    "def summary(prob):\n",
    "    div = '---------------------------------------\\n'\n",
    "    print(\"Variables:\\n\")\n",
    "    score = str(prob.objective)\n",
    "    constraints = [str(const) for const in prob.constraints.values()]\n",
    "    for v in prob.variables():\n",
    "        score = score.replace(v.name, str(v.varValue))\n",
    "        constraints = [const.replace(v.name, str(v.varValue)) for const in constraints]\n",
    "        if v.varValue != 0:\n",
    "            print(v.name, \"=\", v.varValue)\n",
    "    print(div)\n",
    "    print(\"Constraints:\")\n",
    "    for constraint in constraints:\n",
    "        constraint_pretty = \" + \".join(re.findall(\"[0-9\\.]*\\*1.0\", constraint))\n",
    "        if constraint_pretty != \"\":\n",
    "            print(\"{} = {}\".format(constraint_pretty, eval(constraint_pretty)))\n",
    "    print(div)\n",
    "    print(\"Score:\")\n",
    "    score_pretty = \" + \".join(re.findall(\"[0-9\\.]+\\*1.0\", score))\n",
    "    print(\"{} = {}\".format(score_pretty, eval(score)))\n",
    "\n",
    "summary(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eb01d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Josh Allen',\n",
       " 'Darrell Henderson',\n",
       " 'Eno Benjamin',\n",
       " 'Rhamondre Stevenson',\n",
       " 'George Kittle',\n",
       " 'Adam Thielen',\n",
       " 'Cooper Kupp',\n",
       " 'Rondale Moore',\n",
       " 'Patrick Mahomes',\n",
       " 'AJ Dillon',\n",
       " 'Devin Singletary',\n",
       " 'Saquon Barkley',\n",
       " 'Mark Andrews',\n",
       " 'DJ Moore',\n",
       " 'Deebo Samuel',\n",
       " 'Romeo Doubs']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for v in prob.variables():\n",
    "    if v.varValue != 0:\n",
    "        plyr_nm = v.name\n",
    "        plyr_nm = plyr_nm[3:]\n",
    "        plyr_nm = plyr_nm.replace('_', ' ')\n",
    "        ls.append(plyr_nm)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29b7cfdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c16fa22e08fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mruntime_ls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'runtime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'runtime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_latest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'runtime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mruntime_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_earlier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'runtime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mruntime_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_merge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_latest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_earlier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gameID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'playerID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ff_test2.csv')\n",
    "runtime_ls = list(df.sort_values(by='runtime', ascending=False)['runtime'].unique())\n",
    "df_latest = df[df['runtime']==runtime_ls[0]]\n",
    "df_earlier = df[df['runtime']==runtime_ls[1]]     \n",
    "\n",
    "df_merge = pd.merge(df_latest, df_earlier, on=['gameID','playerID'], how='inner')\n",
    "df_merge['Diff']=df_merge['points_x']-df_merge['points_y']\n",
    "\n",
    "df_merge['recyds_x_bool'] = df_merge['recyds_x']>0\n",
    "df_merge['recyds_x_bool'] = df_merge['recyds_x_bool'].replace({True: 1, False: -1})\n",
    "df_merge['recyds_y_bool'] = df_merge['recyds_y']>0\n",
    "df_merge['recyds_y_bool'] = df_merge['recyds_y_bool'].replace({True: 1, False: -1})\n",
    "df_merge['recyds_bool'] = df_merge['recyds_x_bool']*df_merge['recyds_y_bool']\n",
    "\n",
    "df_merge['rushyds_x_bool'] = df_merge['rushyds_x']>0\n",
    "df_merge['rushyds_x_bool'] = df_merge['rushyds_x_bool'].replace({True: 1, False: -1})\n",
    "df_merge['rushyds_y_bool'] = df_merge['rushyds_y']>0\n",
    "df_merge['rushyds_y_bool'] = df_merge['rushyds_y_bool'].replace({True: 1, False: -1})\n",
    "df_merge['rushyds_bool'] = df_merge['rushyds_x_bool']*df_merge['rushyds_y_bool']\n",
    "\n",
    "df_merge['passyds_x_bool'] = df_merge['passyds_x']>0\n",
    "df_merge['passyds_x_bool'] = df_merge['passyds_x_bool'].replace({True: 1, False: -1})\n",
    "df_merge['passyds_y_bool'] = df_merge['passyds_y']>0\n",
    "df_merge['passyds_y_bool'] = df_merge['passyds_y_bool'].replace({True: 1, False: -1})\n",
    "df_merge['passyds_bool'] = df_merge['passyds_x_bool']*df_merge['passyds_y_bool']\n",
    "\n",
    "df_merge['recs_x_bool'] = df_merge['recs_x']>0\n",
    "df_merge['recs_x_bool'] = df_merge['recs_x_bool'].replace({True: 1, False: -1})\n",
    "df_merge['recs_y_bool'] = df_merge['recs_y']>0\n",
    "df_merge['recs_y_bool'] = df_merge['recs_y_bool'].replace({True: 1, False: -1})\n",
    "df_merge['recs_bool'] = df_merge['recs_x_bool']*df_merge['recs_y_bool']\n",
    "\n",
    "df_merge['anytd_x_bool'] = df_merge['anytd_x']>=5000\n",
    "df_merge['anytd_x_bool'] = df_merge['anytd_x_bool'].replace({True: 1, False: -1})\n",
    "df_merge['anytd_y_bool'] = df_merge['anytd_y']>=5000\n",
    "df_merge['anytd_y_bool'] = df_merge['anytd_y_bool'].replace({True: 1, False: -1})\n",
    "df_merge['anytd_bool'] = df_merge['anytd_x_bool']*df_merge['anytd_y_bool']\n",
    "\n",
    "#df_merge = df_merge[np.where((df_merge['anytd_bool']==1)&(df_merge['recs_bool']==1)&(df_merge['recyds_bool']==1)&(df_merge['rushyds_bool']==1)&(df_merge['passyds_bool']==1))]\n",
    "df_merge['bool'] = df_merge['anytd_bool']+df_merge['recs_bool']+df_merge['recyds_bool']+df_merge['rushyds_bool']+df_merge['passyds_bool']\n",
    "df_merge = df_merge[df_merge['bool'] == 5]\n",
    "\n",
    "df_merge.sort_values(by='Diff', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9455ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('Diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418bb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
